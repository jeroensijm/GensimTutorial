{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/gensim-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. How to create the TFIDF matrix (corpus) in gensim?\n",
    "\n",
    "The Term Frequency â€“ Inverse Document Frequency(TF-IDF) is also a bag-of-words model but unlike the regular corpus, TFIDF down weights tokens (words) that appears frequently across documents.\n",
    "\n",
    "How is TFIDF computed?\n",
    "\n",
    "Tf-Idf is computed by multiplying a local component like term frequency (TF) with a global component, that is, inverse document frequency (IDF) and optionally normalizing the result to unit length.\n",
    "\n",
    "As a result of this, the words that occur frequently across documents will get downweighted.\n",
    "\n",
    "There are multiple variations of formulas for TF and IDF existing. Gensim uses the SMART Information retrieval system that can be used to implement these variations. You can specify what formula to use specifying the smartirs parameter in the TfidfModel. See help(models.TfidfModel) for more details. \n",
    "So, how to get the TFIDF weights?\n",
    "\n",
    "By training the corpus with models.TfidfModel(). Then, apply the corpus within the square brackets of the trained tfidf model. See example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['first', 1], ['is', 1], ['line', 1], ['the', 1], ['this', 1]]\n",
      "[['is', 1], ['the', 1], ['this', 1], ['second', 1], ['sentence', 1]]\n",
      "[['this', 1], ['document', 1], ['third', 1]]\n",
      "\n",
      "[['first', 0.66], ['is', 0.24], ['line', 0.66], ['the', 0.24]]\n",
      "[['is', 0.24], ['the', 0.24], ['second', 0.66], ['sentence', 0.66]]\n",
      "[['document', 0.71], ['third', 0.71]]\n"
     ]
    }
   ],
   "source": [
    "# from gensim import models\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "\n",
    "documents = [\"This is the first line\",\n",
    "             \"This is the second sentence\",\n",
    "             \"This third document\"]\n",
    "\n",
    "# Create the Dictionary and Corpus\n",
    "mydict = corpora.Dictionary([simple_preprocess(line) for line in documents])\n",
    "corpus = [mydict.doc2bow(simple_preprocess(line)) for line in documents]\n",
    "\n",
    "# Show the Word Weights in Corpus\n",
    "for doc in corpus:\n",
    "    print([[mydict[id], freq] for id, freq in doc])\n",
    "\n",
    "# [['first', 1], ['is', 1], ['line', 1], ['the', 1], ['this', 1]]\n",
    "# [['is', 1], ['the', 1], ['this', 1], ['second', 1], ['sentence', 1]]\n",
    "# [['this', 1], ['document', 1], ['third', 1]]\n",
    "\n",
    "# Create the TF-IDF model\n",
    "tfidf = models.TfidfModel(corpus, smartirs='ntc')\n",
    "\n",
    "print(\"\")\n",
    "# Show the TF-IDF weights\n",
    "for doc in tfidf[corpus]:\n",
    "    print([[mydict[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
    "# [['first', 0.66], ['is', 0.24], ['line', 0.66], ['the', 0.24]]\n",
    "# [['is', 0.24], ['the', 0.24], ['second', 0.66], ['sentence', 0.66]]\n",
    "# [['document', 0.71], ['third', 0.71]]\n",
    "\n",
    "# !! the word 'this' was removed as it appeared in all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GensimTut_Python3.7",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
